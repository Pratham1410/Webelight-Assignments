{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y8-DYVUCpPTS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "movies_df = pd.read_csv('tmdb_5000_movies.csv')\n",
        "credits_df = pd.read_csv('tmdb_5000_credits.csv')\n",
        "\n",
        "merged_df = movies_df.merge(credits_df, on='title')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# Function to convert JSON-like string to a list of names\n",
        "def parse_names(data):\n",
        "    try:\n",
        "        return [item['name'] for item in ast.literal_eval(data)]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "# Function to get the top N cast members\n",
        "def get_top_cast(data, n=3):\n",
        "    try:\n",
        "        return [item['name'] for item in ast.literal_eval(data)[:n]]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "# Function to get the director's name from crew\n",
        "def get_director(data):\n",
        "    try:\n",
        "        for item in ast.literal_eval(data):\n",
        "            if item['job'] == 'Director':\n",
        "                return item['name']\n",
        "        return ''\n",
        "    except (ValueError, SyntaxError):\n",
        "        return ''\n",
        "\n",
        "merged_df['genres'] = merged_df['genres'].apply(parse_names)\n",
        "merged_df['keywords'] = merged_df['keywords'].apply(parse_names)\n",
        "merged_df['cast'] = merged_df['cast'].apply(lambda x: get_top_cast(x, n=3))\n",
        "merged_df['director'] = merged_df['crew'].apply(get_director)\n",
        "\n",
        "merged_df['overview'] = merged_df['overview'].fillna('')\n",
        "merged_df['director'] = merged_df['director'].fillna('')\n",
        "\n",
        "merged_df['combined_features'] = merged_df.apply(\n",
        "    lambda x: ' '.join(x['genres']) + ' ' +\n",
        "              ' '.join(x['keywords']) + ' ' +\n",
        "              ' '.join(x['cast']) + ' ' +\n",
        "              x['director'] + ' ' +\n",
        "              x['overview'],\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZpwoBBZJp1vQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Vectorizing the combined features\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "count_matrix = count_vectorizer.fit_transform(merged_df['combined_features'])\n",
        "#Calculating the cosine similarity\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n"
      ],
      "metadata": {
        "id": "Aovd2eS8qN_z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "merged_df['encoded_title'] = label_encoder.fit_transform(merged_df['title'])\n",
        "\n",
        "# Neural network model\n",
        "input_layer = Input(shape=(count_matrix.shape[1],))\n",
        "dense_layer_1 = Dense(512, activation='relu')(input_layer)\n",
        "dense_layer_2 = Dense(256, activation='relu')(dense_layer_1)\n",
        "dense_layer_3 = Dense(128, activation='relu')(dense_layer_2)\n",
        "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer_3)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(count_matrix.toarray(), merged_df['encoded_title'], epochs=10, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHh_nHhMrCVC",
        "outputId": "90fa0953-d0c3-4f3b-c864-3cd9f0af6149"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 8.4870 - accuracy: 2.5994e-04 - val_loss: 8.5037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 8.4199 - accuracy: 0.0099 - val_loss: 8.6311 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 7.6533 - accuracy: 0.0060 - val_loss: 9.6129 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 4.4525 - accuracy: 0.3054 - val_loss: 13.9293 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.8780 - accuracy: 0.8485 - val_loss: 19.2442 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.0833 - accuracy: 0.9867 - val_loss: 21.0668 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 21.3466 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 5s 76ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 21.8057 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 5s 74ms/step - loss: 7.8788e-04 - accuracy: 1.0000 - val_loss: 22.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 5.8084e-04 - accuracy: 1.0000 - val_loss: 22.4975 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7907a416e440>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = pd.Series(merged_df.index, index=merged_df['title']).drop_duplicates()\n",
        "\n",
        "def get_cb_recommendations(title, cosine_sim=cosine_sim, top_n=5):\n",
        "    if title not in indices:\n",
        "        return []\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:top_n+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return merged_df['title'].iloc[movie_indices].tolist()\n",
        "\n",
        "def get_nn_recommendations(title, model=model, top_n=5):\n",
        "    if title not in indices:\n",
        "        return []\n",
        "    idx = indices[title]\n",
        "    input_vec = count_matrix[idx].toarray()\n",
        "    preds = model.predict(input_vec)\n",
        "    recommended_indices = preds.argsort()[0][-top_n:][::-1]\n",
        "    recommended_titles = label_encoder.inverse_transform(recommended_indices)\n",
        "    return recommended_titles.tolist()\n",
        "\n",
        "# Combining the both model\n",
        "def get_combined_recommendations(title, top_n=10):\n",
        "    cb_recs = get_cb_recommendations(title, top_n=top_n//2)\n",
        "    nn_recs = get_nn_recommendations(title, top_n=top_n//2)\n",
        "    combined_recs = list(dict.fromkeys(cb_recs + nn_recs))\n",
        "    return combined_recs\n",
        "\n",
        "print(get_combined_recommendations('Cars 2'))\n"
      ],
      "metadata": {
        "id": "YMVM4b72rM41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17d6b4d-b5d0-42ca-ec6d-6d052742e3f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "['Cars', 'Herbie Fully Loaded', 'The Final Destination', 'Furious 7', 'The Fast and the Furious: Tokyo Drift', 'Cars 2', 'Jonah: A VeggieTales Movie', 'Made of Honor', 'Cheaper by the Dozen', 'Without a Paddle']\n"
          ]
        }
      ]
    }
  ]
}
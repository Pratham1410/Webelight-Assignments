{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y8-DYVUCpPTS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "movies_df = pd.read_csv('tmdb_5000_movies.csv')\n",
        "credits_df = pd.read_csv('tmdb_5000_credits.csv')\n",
        "\n",
        "merged_df = movies_df.merge(credits_df, on='title')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# Function to convert JSON-like string to a list of names\n",
        "def parse_names(data):\n",
        "    try:\n",
        "        return [item['name'] for item in ast.literal_eval(data)]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "# Function to get the top N cast members\n",
        "def get_top_cast(data, n=3):\n",
        "    try:\n",
        "        return [item['name'] for item in ast.literal_eval(data)[:n]]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "# Function to get the director's name from crew\n",
        "def get_director(data):\n",
        "    try:\n",
        "        for item in ast.literal_eval(data):\n",
        "            if item['job'] == 'Director':\n",
        "                return item['name']\n",
        "        return ''\n",
        "    except (ValueError, SyntaxError):\n",
        "        return ''\n",
        "\n",
        "merged_df['genres'] = merged_df['genres'].apply(parse_names)\n",
        "merged_df['keywords'] = merged_df['keywords'].apply(parse_names)\n",
        "merged_df['cast'] = merged_df['cast'].apply(lambda x: get_top_cast(x, n=3))\n",
        "merged_df['director'] = merged_df['crew'].apply(get_director)\n",
        "\n",
        "merged_df['overview'] = merged_df['overview'].fillna('')\n",
        "merged_df['director'] = merged_df['director'].fillna('')\n",
        "\n",
        "merged_df['combined_features'] = merged_df.apply(\n",
        "    lambda x: ' '.join(x['genres']) + ' ' +\n",
        "              ' '.join(x['keywords']) + ' ' +\n",
        "              ' '.join(x['cast']) + ' ' +\n",
        "              x['director'] + ' ' +\n",
        "              x['overview'],\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZpwoBBZJp1vQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Vectorizing the combined features\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "count_matrix = count_vectorizer.fit_transform(merged_df['combined_features'])\n",
        "#Calculating the cosine similarity\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n"
      ],
      "metadata": {
        "id": "Aovd2eS8qN_z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "merged_df['encoded_title'] = label_encoder.fit_transform(merged_df['title'])\n",
        "\n",
        "# Neural network model\n",
        "input_layer = Input(shape=(count_matrix.shape[1],))\n",
        "dense_layer_1 = Dense(512, activation='relu')(input_layer)\n",
        "dense_layer_2 = Dense(256, activation='relu')(dense_layer_1)\n",
        "dense_layer_3 = Dense(128, activation='relu')(dense_layer_2)\n",
        "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer_3)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(count_matrix.toarray(), merged_df['encoded_title'], epochs=10, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHh_nHhMrCVC",
        "outputId": "3ad81f0e-c296-4c6c-e6c4-d06336294ac1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "61/61 [==============================] - 6s 78ms/step - loss: 8.4870 - accuracy: 7.7983e-04 - val_loss: 8.5039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "61/61 [==============================] - 4s 70ms/step - loss: 8.4056 - accuracy: 0.0031 - val_loss: 8.6987 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 7.5131 - accuracy: 0.0083 - val_loss: 9.5739 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "61/61 [==============================] - 4s 70ms/step - loss: 4.0064 - accuracy: 0.3582 - val_loss: 14.0763 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.6668 - accuracy: 0.8861 - val_loss: 20.1073 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.0671 - accuracy: 0.9909 - val_loss: 21.7457 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 22.1372 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 22.3128 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 8.7420e-04 - accuracy: 1.0000 - val_loss: 22.6584 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "61/61 [==============================] - 5s 74ms/step - loss: 6.4948e-04 - accuracy: 1.0000 - val_loss: 22.9323 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c4c9408d960>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = pd.Series(merged_df.index, index=merged_df['title']).drop_duplicates()\n",
        "\n",
        "def get_cb_recommendations(title, cosine_sim=cosine_sim, top_n=5):\n",
        "    if title not in indices:\n",
        "        return []\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:top_n+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return merged_df['title'].iloc[movie_indices].tolist()\n",
        "\n",
        "def get_nn_recommendations(title, model=model, top_n=5):\n",
        "    if title not in indices:\n",
        "        return []\n",
        "    idx = indices[title]\n",
        "    input_vec = count_matrix[idx].toarray()\n",
        "    preds = model.predict(input_vec)\n",
        "    recommended_indices = preds.argsort()[0][-top_n:][::-1]\n",
        "    recommended_titles = label_encoder.inverse_transform(recommended_indices)\n",
        "    return recommended_titles.tolist()\n",
        "\n",
        "# Combining the both model\n",
        "def get_combined_recommendations(title, top_n=10):\n",
        "    cb_recs = get_cb_recommendations(title, top_n=top_n//2)\n",
        "    nn_recs = get_nn_recommendations(title, top_n=top_n//2)\n",
        "    combined_recs = list(dict.fromkeys(cb_recs + nn_recs))\n",
        "    return combined_recs\n",
        "\n",
        "print(get_combined_recommendations('The Avengers'))\n",
        "print(get_combined_recommendations('Avatar'))\n",
        "print(get_combined_recommendations('Titanic'))\n",
        "print(get_combined_recommendations('Jurassic World'))\n",
        "print(get_combined_recommendations(\"Pirates of the Caribbean: At World's End\"))\n",
        "print(get_combined_recommendations('The Dark Knight Rises'))\n"
      ],
      "metadata": {
        "id": "YMVM4b72rM41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5e07cc-e0dc-43c6-80e5-05810da294dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "['Avengers: Age of Ultron', 'Captain America: Civil War', 'Iron Man 2', 'Fantastic Four', 'Iron Man', 'The Avengers', 'Superman II', 'Re-Kill']\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "['Aliens', 'Moonraker', 'Mission to Mars', 'AlienÂ³', 'Alien', 'Avatar', 'Wing Commander', 'Flash Gordon']\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "['The Notebook', 'Romance & Cigarettes', 'Captain Phillips', 'Four Weddings and a Funeral', 'Love Letters', 'Titanic', 'Self/less', 'Green Street Hooligans: Underground', 'Patton', 'Ghost Ship']\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "['Jurassic Park', 'The Lost World: Jurassic Park', 'Jurassic Park III', 'Vacation', 'The Nut Job', 'Jurassic World', 'Scooby-Doo', 'The Chronicles of Riddick']\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[\"Pirates of the Caribbean: Dead Man's Chest\", 'Pirates of the Caribbean: The Curse of the Black Pearl', 'Pirates of the Caribbean: On Stranger Tides', 'The Imaginarium of Doctor Parnassus', 'Cyrus', \"Pirates of the Caribbean: At World's End\", 'Dolphins and Whales: Tribes of the Ocean', 'Soul Survivors']\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "['The Dark Knight', 'Batman Begins', 'Batman', 'Batman Returns', 'The Dark Knight Rises', 'Dude, Whereâs My Car?', 'Trust', 'Salton Sea']\n"
          ]
        }
      ]
    }
  ]
}